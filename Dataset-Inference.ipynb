{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "此部分为Dataset Inference部分代码的解构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset Inference\n",
    "Dataset Inference的核心思想是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('.')\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from funcs import load_dataset\n",
    "from funcs import test\n",
    "from funcs import get_student_teacher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "parse = argparse.ArgumentParser()\n",
    "parse.add_argument('--dataset_path', type=str, default='', help=\"dataset path\")\n",
    "parse.add_argument('--batch_size', type=int, default=100)\n",
    "parse.add_argument('--epoch', type=int, default=20)\n",
    "parse.add_argument('--device', type=str, default='cuda')\n",
    "parse.add_argument('--model_root', type=str, default='')\n",
    "parse.add_argument('--num_classes', type=int, default=10)\n",
    "parse.add_argument('--distance', type=str, default=None)\n",
    "parse.add_argument('--file_dir', type=str, default='',help=\"格式为./feature/数据库名/模型的编号或名称/\")\n",
    "parse.add_argument('--dataset',type=str, default='CIFAR10',choices=['CIFAR10','self'])\n",
    "parse.add_argument('--mode', type=str, default='teacher')\n",
    "parse.add_argument('--normalize', type=int, default=1)\n",
    "args = parse.parse_args(args=['--dataset_path','',\n",
    "                              '--batch_size', '100',\n",
    "                              '--epoch', '20',\n",
    "                              '--device', 'cuda',\n",
    "                              '--model_root', './trained/CIFAR10/test/final.pt',\n",
    "                              '--num_classes', '10',\n",
    "                              '--distance', 'None',\n",
    "                              '--file_dir', './feature/CIFAR10/test/',\n",
    "                              '--dataset', 'CIFAR10',\n",
    "                              '--normalize', '1',\n",
    "                              '--mode', 'teacher',\n",
    "                              ])\n",
    "print(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rand_steps(model, X, y, args, target=None):\n",
    "    # 盲步\n",
    "    # X 是一个sample\n",
    "    # y 是X所对应的标签\n",
    "    # target 感觉没啥意义\n",
    "    del target\n",
    "    start = time.time()\n",
    "    is_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    # 定义噪声\n",
    "    uni, std, scale = (0.005, 0.005, 0.01)\n",
    "    steps = 50\n",
    "    # 设定随机的步数\n",
    "    noise_2 = lambda X: torch.normal(0, std, size=X.shape).cuda()\n",
    "    noise_1 = lambda X: torch.from_numpy(np.random.laplace(loc=0.0, scale=scale, size=X.shape)).float().to(args.device)\n",
    "    noise_inf = lambda X: torch.empty_like(X).uniform_(-uni, uni)\n",
    "    noise_map = {\"l1\": noise_1, \"l2\": noise_2, \"linf\": noise_inf}\n",
    "    mag = 1\n",
    "    # mag 表示步进的程度，mag逐渐加大\n",
    "\n",
    "    delta = noise_map[args.distance](X)\n",
    "    delta_base = delta.clone()\n",
    "    delta.data = torch.min(torch.max(delta.detach(), -X), 1 - X)\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for t in range(steps):\n",
    "            if t > 0:\n",
    "                preds = model(X_r + delta_r)\n",
    "                # X_r + delta_r 表示施加噪声后预测仍然为y的点\n",
    "                new_remaining = (preds.max(1)[1] == y[remaining])\n",
    "                remaining_temp = remaining.clone()\n",
    "                remaining[remaining_temp] = new_remaining\n",
    "                # 更新remaining状态\n",
    "            else:\n",
    "                preds = model(X + delta)\n",
    "                # preds 表示从model中得到此时X+噪声后的预测分布\n",
    "                remaining = (preds.max(1)[1] == y)\n",
    "                # remaining 表示预测概率的第一维中最大值的索引是否为y，即预测未发生改变的点的索引\n",
    "\n",
    "            if remaining.sum() == 0: break\n",
    "            # 当remaining中所有预测都与y不同，则表示转换完成，结束rand_step\n",
    "\n",
    "            X_r = X[remaining]\n",
    "            # X_r 表示X中仍然预测为y的点\n",
    "            delta_r = delta[remaining]\n",
    "            # delta[remaining] 表示在X_r处的噪声\n",
    "            preds = model(X_r + delta_r)\n",
    "            mag += 1\n",
    "            delta_r = delta_base[remaining] * mag\n",
    "            # 加深预测未发生改变处的噪声\n",
    "            delta_r.data = torch.min(torch.max(delta_r.detach(), -X_r), 1 - X_r)\n",
    "            # 截取 X+delta_r[remaining] 至 [0, 1]\n",
    "            delta[remaining] = delta_r.detach()\n",
    "            # delta与delta_r共享内存\n",
    "        # print(\n",
    "        #    f\"Number of steps = {t + 1} | Failed to convert = {(model(X + delta).max(1)[1] == y).sum().item()} | Time taken = {time.time() - start}\")\n",
    "        # 输出结果，Failed to convert表示在施加噪声的最大值后也未改变预测的点的个数\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    return delta\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def norms(Z):\n",
    "    return Z.view(Z.shape[0], -1).norm(dim=1)[:, None, None, None]\n",
    "\n",
    "def norms_linf_squeezed(Z):\n",
    "    return Z.view(Z.shape[0], -1).abs().max(dim=1)[0]\n",
    "\n",
    "def norms_l1_squeezed(Z):\n",
    "    return Z.view(Z.shape[0], -1).abs().sum(dim=1)[:, None, None, None].squeeze(1).squeeze(1).squeeze(1)\n",
    "\n",
    "def norms_l2_squeezed(Z):\n",
    "    return norms(Z).squeeze(1).squeeze(1).squeeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_random_label_only(args, loader, model, num_images = 1000):\n",
    "    print(\"getting random attacks\")\n",
    "    batch_size = args.batch_size\n",
    "    max_iter = num_images/batch_size\n",
    "    # max_iter\n",
    "    lp_dist = [[],[],[]]\n",
    "    # lp_dist 表示三种范数计算下的distance\n",
    "    ex_skipped = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        # if args.regressor_embed == 1: ##We need an extra set of `distinct images for training the confidence regressor\n",
    "        #    if(ex_skipped < num_images):\n",
    "        #        y = batch[1]\n",
    "        #        ex_skipped += y.shape[0]\n",
    "        #        continue\n",
    "        # 原论文中还有上面这部分代码，但我不是很理解作用\n",
    "        for j, distance in enumerate([\"linf\", \"l2\", \"l1\"]):\n",
    "            temp_list = []\n",
    "            for target_i in range(10):\n",
    "                # 反复计算以增加鲁棒性\n",
    "                X, y = batch[0].to(args.device), batch[1].to(args.device)\n",
    "                args.distance = distance\n",
    "                # 此处distance为None\n",
    "                preds = model(X)\n",
    "                targets = None\n",
    "                delta = rand_steps(model, X, y, args, target = targets)\n",
    "                # delta 为将sample X中一点的预测发生改变时所需要的最小的噪声\n",
    "                yp = model(X + delta)\n",
    "                distance_dict = {\"linf\": norms_linf_squeezed, \"l1\":norms_l1_squeezed, \"l2\": norms_l2_squeezed}\n",
    "                distances = distance_dict[distance](delta)\n",
    "                # 不是很理解这个地方的数学意义\n",
    "                temp_list.append(distances.cpu().detach().unsqueeze(-1))\n",
    "            temp_dist = torch.cat(temp_list, dim=1)\n",
    "            lp_dist[j].append(temp_dist)\n",
    "        if i+1 >= max_iter:\n",
    "            break\n",
    "\n",
    "    lp_d = [torch.cat(lp_dist[i], dim=0).unsqueeze(-1) for i in range(3)]\n",
    "    full_d = torch.cat(lp_d, dim=-1)\n",
    "    print(full_d.shape)\n",
    "    return full_d\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def feature_extractor(args):\n",
    "    print(args)\n",
    "    train_loader, test_loader = load_dataset(args)\n",
    "    student, _ = get_student_teacher(args)\n",
    "    student.train()\n",
    "    student = student.to(args.device)\n",
    "    student.load_state_dict(torch.load(args.model_root), strict=False)\n",
    "    student.eval()\n",
    "    print(test(student, test_loader, args))\n",
    "\n",
    "    file_dir = args.file_dir\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "\n",
    "    test_d = get_random_label_only(args, test_loader, student)\n",
    "    print(test_d)\n",
    "\n",
    "    torch.save(test_d, f\"{args.file_dir}test_rand.pt\")\n",
    "\n",
    "    train_d = get_random_label_only(args, train_loader, student)\n",
    "    print(train_d)\n",
    "    torch.save(train_d, f\"{args.file_dir}train_rand.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_extractor(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 通过prediction margin来训练一个二元分类器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from importlib import reload\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import combine_pvalues, ttest_ind_from_stats, ttest_ind\n",
    "from functools import reduce\n",
    "from scipy.stats import hmean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split_index = 500\n",
    "root = args.file_dir\n",
    "train_root = root + 'train_rand.pt'\n",
    "test_root = root + 'test_rand.pt'\n",
    "trains = torch.load(train_root)\n",
    "tests = torch.load(test_root)\n",
    "\n",
    "mean_cifar = trains.mean(dim=(0, 1))\n",
    "std_cifar = trains.std(dim=(0, 1))\n",
    "\n",
    "trains = (trains - mean_cifar)/std_cifar\n",
    "tests = (tests - mean_cifar)/std_cifar\n",
    "\n",
    "f_num = 30\n",
    "a_num = 30\n",
    "\n",
    "trains_n = trains.T.reshape(1000, f_num)[:, :a_num]\n",
    "tests_n = tests.T.reshape(1000, f_num)[:, :a_num]\n",
    "\n",
    "n_ex = split_index\n",
    "train = torch.cat((trains_n[:n_ex], tests_n[:n_ex]), dim=0)\n",
    "y = torch.cat((torch.zeros(n_ex), torch.ones(n_ex)), dim=0)\n",
    "\n",
    "rand = torch.randperm(y.shape[0])\n",
    "train = train[rand]\n",
    "y = y[rand]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(a_num, 100),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(100, 1),\n",
    "                      nn.Tanh())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tqdm(range(1000)) as pbar:\n",
    "    for epoch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = train\n",
    "        outputs = model(inputs)\n",
    "        loss = -1 * ((2 * y - 1) * (outputs.squeeze(-1))).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description('loss {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 计算p-value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_p(outputs_train, outputs_test):\n",
    "    # 计算两个样本的p-value\n",
    "    pred_test = outputs_test[:,0].detach().cpu().numpy()\n",
    "    pred_train = outputs_train[:,0].detach().cpu().numpy()\n",
    "\n",
    "    tval, pval = ttest_ind(pred_test, pred_train, alternative=\"greater\", equal_var=False)\n",
    "    # ttest_ind 计算两个独立分数样本的平均T-test，是对两个独立样本拥有相同平均值的零假设的检验\n",
    "    # alternative greater：推测第一个样本的分布平均值大于第二个样本的分布平均值\n",
    "    # equal_var false: 执行 Welch 的 T-test，该检验不假定总体方差相等\n",
    "    # 详见https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#r3566833beaa2-2\n",
    "\n",
    "    if pval < 0:\n",
    "        raise Exception(f\"p-value={pval}\")\n",
    "    return pval\n",
    "\n",
    "def get_p_values(num_ex, train, test, k):\n",
    "    total = train.shape[0]\n",
    "    sum_p = 0\n",
    "    p_values = []\n",
    "    positions_list = []\n",
    "    for i in range(k):\n",
    "        positions = torch.randperm(total)[:num_ex]\n",
    "        # positions 0~total-1个随机排列的前num_ex个数\n",
    "        p_val = get_p(train[positions], test[positions])\n",
    "        # p_val 随机计算train和test的 与positions对应的样本之间的 p-val值\n",
    "        positions_list.append(positions)\n",
    "        p_values.append(p_val)\n",
    "    return p_values\n",
    "\n",
    "def get_fischer(num_ex, train, test, k):\n",
    "    p_values = get_p_values(num_ex, train, test, k)\n",
    "    return combine_pvalues(p_values, method=\"mudholkar_george\")[1]\n",
    "\n",
    "def get_max_p_value(num_ex, train, test, k):\n",
    "    p_values = get_p_values(num_ex, train, test, k)\n",
    "    return max(p_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def print_inference(outputs_train, outputs_test):\n",
    "    m1, m2 = outputs_test[:,0].mean(), outputs_train[:,0].mean()\n",
    "    pval = get_p(outputs_train, outputs_test)\n",
    "    print(f\"p-value = {pval} \\t| Mean difference = {m1-m2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sus_root = \"./feature/CIFAR10/test/\"\n",
    "# sus_root 表示可疑模型由Embedding Generation得到的数据地址\n",
    "sus_train = torch.load(sus_root + 'train_rand.pt')\n",
    "sus_test = torch.load(sus_root + 'test_rand.pt')\n",
    "\n",
    "sus_train = (sus_train - mean_cifar)/std_cifar\n",
    "sus_test = (sus_test - mean_cifar)/std_cifar\n",
    "\n",
    "sus_train_n = sus_train.T.reshape(1000, f_num)[:, :a_num]\n",
    "sus_test_n = sus_test.T.reshape(1000, f_num)[:, :a_num]\n",
    "\n",
    "sus_output_tr = model(sus_train_n)\n",
    "sus_output_te = model(sus_test_n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vic_output_tr = model(trains_n)\n",
    "vic_output_te = model(tests_n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sus_output_te, sus_output_tr = sus_output_te[split_index:], sus_output_tr[split_index:]\n",
    "vic_output_te, vic_output_tr = vic_output_te[split_index:], vic_output_tr[split_index:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_inference(sus_output_tr, sus_output_te)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_inference(vic_output_tr, vic_output_te)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0 \t| Mean difference = 1.8227035999298096\n"
     ]
    }
   ],
   "source": [
    "print_inference(vic_output_tr, vic_output_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}